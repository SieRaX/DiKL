# Diffusive KL Divergence (DiKL)
Official PyTorch implementation of paper [Training Neural Samplers with Reverse Diffusive KL Divergence](https://arxiv.org/abs/2410.12456).

## Reproducing results for DiKL and Baselines
